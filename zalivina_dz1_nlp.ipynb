{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=UTF-8\n",
    "from bs4 import BeautifulSoup \n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_in_dict(soup):\n",
    "    d_com = {}\n",
    "    text_full = soup.find_all(\"div\", attrs={\"class\": \"responses__item__message markup-inside-small markup-inside-small--bullet\"})\n",
    "    regex = r\"<.+>\"\n",
    "    comments_clean = []\n",
    "    for each in text_full:\n",
    "        result = re.sub(regex, '', str(each), 0, re.MULTILINE)\n",
    "        result = result.replace('\\n', '')\n",
    "        result = result.replace('\\t', '')\n",
    "        result = result.replace('\\xa0', '')\n",
    "        comments_clean.append(result)\n",
    "        time.sleep(random.uniform(3.2,5.4))\n",
    "    return comments_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:34<00:00, 111.57s/it]\n",
      "100%|██████████| 3/3 [05:25<00:00, 108.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# x - оценка, y - страница \n",
    "database = {}\n",
    "votes = [1,5]\n",
    "for x in votes:\n",
    "    for y in tqdm(range(1,4)):\n",
    "        url = 'https://www.banki.ru/services/responses/bank/sberbank/?rate='+ str(x) +'&page='+ str(y) + '&isMobile=0'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        d = writing_in_dict(soup)\n",
    "        a = str(x)+str(y)\n",
    "        database[a] = d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "database['11'].extend(database['12'])\n",
    "database['51'].extend(database['52'])\n",
    "database['13'].extend(database['53'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dict = {}\n",
    "pos_list = []\n",
    "neg_list = []\n",
    "for each in database['13']:\n",
    "    if each != '':\n",
    "        if each in database['53']:\n",
    "            pos_list.append(each)\n",
    "        else:\n",
    "            neg_list.append(each)\n",
    "control_dict['pos'] = pos_list\n",
    "control_dict['neg'] = neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_coments = database['11']\n",
    "pos_coments = database['51']\n",
    "control_group = database['13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_comments_30 = random.sample(neg_coments, 30)\n",
    "pos_comments_30 = random.sample(pos_coments, 30)\n",
    "control = random.sample(control_group, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_pos = ''.join(pos_comments_30)\n",
    "str_neg = ''.join(neg_comments_30)\n",
    "str_control = ''.join(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pos = [w.lower() for w in word_tokenize(str_pos) if w.isalpha()]\n",
    "words_neg = [w.lower() for w in word_tokenize(str_neg) if w.isalpha()]\n",
    "sw = stopwords.words('russian')\n",
    "filtered_pos = [w for w in words_pos if w not in sw]\n",
    "filtered_neg = [w for w in words_neg if w not in sw]\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "lemmas_pos = []\n",
    "for word in filtered_pos:\n",
    "    lemmas_pos.append(morph.parse(word)[0].normal_form)\n",
    "lemmas_neg = []\n",
    "for word in filtered_neg:\n",
    "    lemmas_neg.append(morph.parse(word)[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_pos = Counter()\n",
    "for word in lemmas_pos:\n",
    "    cnt_pos[word] += 1\n",
    "cnt_neg = Counter()\n",
    "for word in lemmas_neg:\n",
    "    cnt_neg[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pos = {}\n",
    "d_neg = {}\n",
    "for key in dict(cnt_pos):\n",
    "    if key not in dict(cnt_neg).keys() and cnt_pos[key]>1:\n",
    "        d_pos[key] = cnt_pos[key]\n",
    "for key in dict(cnt_neg):\n",
    "    if key not in dict(cnt_pos).keys() and cnt_neg[key]>1:\n",
    "        d_neg[key] = cnt_neg[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_lists = {}\n",
    "freq_lists['pos'] = d_pos\n",
    "freq_lists['neg'] = d_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_comment(freq_lists, text):\n",
    "    counts = Counter()\n",
    "    for emotion, freq_list in freq_lists.items():\n",
    "        freq_list = Counter(freq_list)\n",
    "        words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
    "        filtered = [w for w in words if w not in sw]\n",
    "        lemmas = []\n",
    "        for word in filtered:\n",
    "            lemmas.append(morph.parse(word)[0].normal_form)\n",
    "        for word in lemmas:\n",
    "            counts[emotion] += int(freq_list[word] > 0)\n",
    "    return counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хочу выразить благодарность сотрудникам Сбербанка Виноградовой Татьяне Викторовне и Потаповой Оксане Владимировне, за их чуткий подход и заботу о клиентах. Обратилась с запутанным вопросом по поводу наследства и выплаты средств, как можно скорее, в итоге помогли быстро и понятно все разрешить. Прошу руководства обратить внимание на профессионализм данных сотрудников и примеривать по итогам месяца.Теперь по всем банковским вопросам будем с семьей обращаться в ваше отделение.\n"
     ]
    }
   ],
   "source": [
    "test_texts = random.choice(control_group)\n",
    "print(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pos', 7), ('neg', 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_comment(freq_lists, test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_detect_comment(freq_lists, test_size):\n",
    "    results = []  # результаты\n",
    "    gold = []     # исходная эмоция\n",
    "    for emotion in ['pos', 'neg']:\n",
    "        for text in control_dict[emotion]:\n",
    "            predicted_emotion = detect_comment(freq_lists, text)[0][0]\n",
    "            results.append(predicted_emotion)\n",
    "            gold.append(emotion)\n",
    "    print(\"RESULTS:\")\n",
    "    print(\"%d languages\" % 2)\n",
    "    print(\"Test size: %d texts per emotion\" % test_size)\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "2 languages\n",
      "Test size: 10 texts per emotion\n",
      "Accuracy: 0.8163\n"
     ]
    }
   ],
   "source": [
    "test_detect_comment(freq_lists, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизация программы:\n",
    "1. Запись сразу после Counter'а в словарь\n",
    "2. Сделать одинаковыми по размеру словари тональности (негативных слов получилось больше)\n",
    "3. Выкачать больше отзывов за больший промежуток времени, так как встречались отзывы, которые повторяли ситуацию (например, первый негативный отзыв про банк, второй отзыв с такой же ситуацией, но уже с другими деталями, условно, банк обещал сделать X и Y, но все еще ничего не сделал; аналогично с противоположной ситуацией)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
